{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "import cv2\n",
    "import os\n",
    "from keras.utils import np_utils\n",
    "from tqdm import tqdm, trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder_path = \"real_train\"\n",
    "validate_folder_path = \"real_val\"\n",
    "\n",
    "alphabet = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "alphabet_to_num = dict()\n",
    "num = 0\n",
    "for al in alphabet:\n",
    "    alphabet_to_num[al] = num\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(path):\n",
    "    datas = os.listdir(path)\n",
    "#     processed_data = np.stack([img_to_array(load_img(path + '/' + data).resize((137,51)))/255.0 for data in tqdm(datas)])\n",
    "    processed_data = np.stack([img_to_array(load_img(path + '/' + data).resize((137,51)))/255.0 for data in tqdm(datas)])\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(path):\n",
    "    label_data = [[], [], [], []]\n",
    "    datas = os.listdir(path)\n",
    "    for data in tqdm(datas):\n",
    "        label = data.split('.')[0]\n",
    "        for i in range(len(label)):\n",
    "            label_data[i].append(np_utils.to_categorical(alphabet_to_num[label[i]], num_classes=36))\n",
    "\n",
    "    for i in range(len(label_data)):\n",
    "        label_data[i] = np.array(label_data[i])\n",
    "    return label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "train_datas = os.listdir(train_folder_path)\n",
    "val_datas = os.listdir(validate_folder_path)\n",
    "print(len(train_datas))\n",
    "print(len(val_datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(path):\n",
    "    # Generators for keras must be infinite\n",
    "    datas = os.listdir(path)\n",
    "    iterator = iter(datas)\n",
    "    while True:\n",
    "        data = next(iterator, None)\n",
    "        if not data:\n",
    "            iterator = iter(datas)\n",
    "            data = next(iterator, None)\n",
    "        processed_data = img_to_array(load_img(path + '/' + data).resize((137,51)))/255.0\n",
    "        label = data.split('.')[0]\n",
    "        # Need array shape for (1,36) here\n",
    "        labels = [np.asarray([np_utils.to_categorical(alphabet_to_num[char], num_classes=36)]) for char in label.split('_')[0]]\n",
    "        yield np.asarray([processed_data]), labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'captcha'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-462de1eb4d19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcaptcha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageCaptcha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcust_create_captcha_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackground\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'captcha'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from PIL.ImageDraw import Draw\n",
    "from PIL.ImageFont import truetype\n",
    "from PIL import ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from captcha.image import ImageCaptcha\n",
    "import string\n",
    "def cust_create_captcha_image(chars, color, background, wd, he):\n",
    "        \"\"\"Create the CAPTCHA image itself.\n",
    "        :param chars: text to be generated.\n",
    "        :param color: color of the text.\n",
    "        :param background: color of the background.\n",
    "        The color should be a tuple of 3 numbers, such as (0, 255, 255).\n",
    "        \"\"\" \n",
    "        generator = ImageCaptcha(width=wd, height=he, fonts=['font/BEBAS.ttf'])\n",
    "        \n",
    "        image = Image.new('RGB', (wd, he), background)\n",
    "        draw = Draw(image)\n",
    "\n",
    "        \n",
    "        table  =  []\n",
    "        for  i  in  range( 256 ):\n",
    "            table.append( i * 1.97 )\n",
    "        \n",
    "        def _draw_character(c):\n",
    "            font = truetype('font/BEBAS.ttf', 36)\n",
    "            w, h = draw.textsize(c, font=font)\n",
    "\n",
    "            dx = random.randint(0, 4)\n",
    "            dy = random.randint(0, 6)\n",
    "            im = Image.new('RGB', (w + dx, h + dy))\n",
    "            Draw(im).text((dx, dy), c, font=font, fill=color)\n",
    "\n",
    "#             rotate\n",
    "            im = im.crop(im.getbbox())\n",
    "            im = im.rotate(random.uniform(-15, 15), Image.BILINEAR, expand=1)\n",
    "            return im\n",
    "\n",
    "        images = []\n",
    "        for c in chars:\n",
    "            if random.random() > 0.5:\n",
    "                images.append(_draw_character(\" \"))\n",
    "            images.append(_draw_character(c))\n",
    "            \n",
    "\n",
    "        text_width = sum([im.size[0] for im in images])\n",
    "\n",
    "        width = max(text_width, wd)\n",
    "        image = image.resize((width, he))\n",
    "\n",
    "        average = int(text_width / len(chars))\n",
    "        rand = int(0.25 * average)\n",
    "#         offset = int(average * 0.1)\n",
    "#         print(offset)\n",
    "        offset = rand\n",
    "       \n",
    "    \n",
    "        for im in images:\n",
    "            w, h = im.size\n",
    "            word_h = random.randint(0, int(he - h))\n",
    "            mask = im.convert('L').point(table)\n",
    "#             image.paste(ImageOps.colorize(mask, (0,0,0), (0,0,0)), (offset, int((he - h) / 2)), mask)\n",
    "            image.paste(ImageOps.colorize(mask, (0,0,0), (0,0,0)), (offset, word_h), mask)\n",
    "            offset = offset + w + random.randint(-rand, 0)\n",
    "\n",
    "        if width > wd:\n",
    "            image = image.resize((wd, he))\n",
    "\n",
    "        def create_noise_curve(image, color):\n",
    "            w, h = image.size\n",
    "            points = [-20, 8,140, 40]\n",
    "            start = 180\n",
    "            end = -30\n",
    "            Draw(image).arc(points, start, end, fill=color, width=5)\n",
    "            return image\n",
    "            \n",
    "            \n",
    "        word_img = image\n",
    "        curve_image = Image.new('RGB', (wd, he), \"white\")\n",
    "        image_curve = create_noise_curve(curve_image, \"black\")\n",
    "        pix_curve = np.array(image_curve)\n",
    "        pix_word = np.array(word_img)\n",
    "        \n",
    "        result = pix_word ^ pix_curve\n",
    "        result = ~result \n",
    "        result = result & 211\n",
    "        img = Image.fromarray(np.uint8(result))\n",
    "        \n",
    "        generator.create_noise_dots(img, (0,0,0), width=1, number=50)\n",
    "        generator.create_noise_dots(img, (230,230,230), width=1, number=800)\n",
    "        \n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'captcha'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fbbffb470a98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcaptcha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageCaptcha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcharacters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigits\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascii_uppercase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'captcha'"
     ]
    }
   ],
   "source": [
    "from captcha.image import ImageCaptcha\n",
    "import random\n",
    "import string\n",
    "\n",
    "characters = string.digits + string.ascii_uppercase\n",
    "# width, height, n_len, n_class = 170, 80, 4, len(characters)\n",
    "# generator = ImageCaptcha(width=width, height=height)\n",
    "\n",
    "def data_gen_dynamic(batch_size):\n",
    "#     k = True\n",
    "    while True:\n",
    "        x = []\n",
    "        y = [[],[],[],[]]\n",
    "        for _ in range(batch_size):\n",
    "            random_str = ''.join([random.choice(characters) for j in range(4)])\n",
    "            img = cust_create_captcha_image(random_str, \"white\", \"white\", 137, 51)\n",
    "            x.append(img_to_array(img)/255.0)\n",
    "            for i in range(len(random_str)):\n",
    "                y[i].append(np_utils.to_categorical(alphabet_to_num[random_str[i]], num_classes=36))\n",
    "            \n",
    "            for l in y:\n",
    "                l = np.array(l)\n",
    "                \n",
    "#             y.append([np.asarray([np_utils.to_categorical(alphabet_to_num[char], num_classes=36)]) for char in random_str])\n",
    "#         k = False\n",
    "        yield np.asarray(x), y\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_gen_dynamic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7490b93afd7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_gen_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_gen_dynamic' is not defined"
     ]
    }
   ],
   "source": [
    "for item in data_gen_dynamic(2):\n",
    "    print(item.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 51, 137, 3)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 51, 137, 32)  896         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 49, 135, 32)  9248        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 49, 135, 32)  128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 24, 67, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 24, 67, 32)   0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 24, 67, 64)   18496       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 22, 65, 64)   36928       conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 22, 65, 64)   256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 11, 32, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 11, 32, 64)   0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 11, 32, 128)  73856       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 9, 30, 128)   147584      conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 9, 30, 128)   512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 4, 15, 128)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 4, 15, 128)   0           max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 2, 13, 256)   295168      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 2, 13, 256)   1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 1, 6, 256)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1536)         0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1536)         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "digit1 (Dense)                  (None, 36)           55332       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "digit2 (Dense)                  (None, 36)           55332       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "digit3 (Dense)                  (None, 36)           55332       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "digit4 (Dense)                  (None, 36)           55332       dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 805,424\n",
      "Trainable params: 804,464\n",
      "Non-trainable params: 960\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN_Model\n",
    "input_layer = Input((51, 137, 3))\n",
    "out = input_layer\n",
    "out = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')(out)\n",
    "out = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = MaxPooling2D(pool_size=(2, 2))(out)\n",
    "out = Dropout(0.3)(out)\n",
    "out = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(out)\n",
    "out = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = MaxPooling2D(pool_size=(2, 2))(out)\n",
    "out = Dropout(0.3)(out)\n",
    "out = Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu')(out)\n",
    "out = Conv2D(filters=128, kernel_size=(3, 3), activation='relu')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = MaxPooling2D(pool_size=(2, 2))(out)\n",
    "out = Dropout(0.3)(out)\n",
    "out = Conv2D(filters=256, kernel_size=(3, 3), activation='relu')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = MaxPooling2D(pool_size=(2, 2))(out)\n",
    "out = Flatten()(out)\n",
    "out = Dropout(0.3)(out)\n",
    "out = [Dense(36, name='digit1', activation='softmax')(out),\\\n",
    "    Dense(36, name='digit2', activation='softmax')(out),\\\n",
    "    Dense(36, name='digit3', activation='softmax')(out),\\\n",
    "    Dense(36, name='digit4', activation='softmax')(out)]\n",
    "my_model = Model(inputs=input_layer, outputs=out)\n",
    "losses = {\n",
    "    \"digit1\": \"categorical_crossentropy\",\n",
    "    \"digit2\": \"categorical_crossentropy\",\n",
    "    \"digit3\": \"categorical_crossentropy\",\n",
    "    \"digit4\": \"categorical_crossentropy\"\n",
    "}\n",
    "my_model.compile(loss=losses, optimizer=\"adamax\", metrics=['accuracy'])\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., epochs=300, steps_per_epoch=2001, callbacks=[<keras.ca..., validation_steps=300)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 11.2289 - digit1_loss: 2.5497 - digit2_loss: 2.8538 - digit3_loss: 2.8167 - digit4_loss: 3.0088 - digit1_acc: 0.3108 - digit2_acc: 0.2454 - digit3_acc: 0.2384 - digit4_acc: 0.1919 - val_loss: 8.7716 - val_digit1_loss: 2.5089 - val_digit2_loss: 1.7739 - val_digit3_loss: 1.8688 - val_digit4_loss: 2.6201 - val_digit1_acc: 0.4433 - val_digit2_acc: 0.4667 - val_digit3_acc: 0.4333 - val_digit4_acc: 0.2933\n",
      "Epoch 2/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 5.0048 - digit1_loss: 1.0603 - digit2_loss: 1.2679 - digit3_loss: 1.2411 - digit4_loss: 1.4355 - digit1_acc: 0.6622 - digit2_acc: 0.6027 - digit3_acc: 0.5987 - digit4_acc: 0.5532 - val_loss: 4.3900 - val_digit1_loss: 1.1006 - val_digit2_loss: 0.8707 - val_digit3_loss: 0.8291 - val_digit4_loss: 1.5896 - val_digit1_acc: 0.6867 - val_digit2_acc: 0.7167 - val_digit3_acc: 0.7333 - val_digit4_acc: 0.5500\n",
      "Epoch 3/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 2.5142 - digit1_loss: 0.5453 - digit2_loss: 0.6657 - digit3_loss: 0.6094 - digit4_loss: 0.6938 - digit1_acc: 0.8206 - digit2_acc: 0.7816 - digit3_acc: 0.8081 - digit4_acc: 0.7796 - val_loss: 2.8473 - val_digit1_loss: 0.6529 - val_digit2_loss: 0.6227 - val_digit3_loss: 0.4334 - val_digit4_loss: 1.1383 - val_digit1_acc: 0.7767 - val_digit2_acc: 0.8033 - val_digit3_acc: 0.8633 - val_digit4_acc: 0.6367\n",
      "Epoch 4/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 1.4674 - digit1_loss: 0.3472 - digit2_loss: 0.3994 - digit3_loss: 0.3403 - digit4_loss: 0.3804 - digit1_acc: 0.8836 - digit2_acc: 0.8671 - digit3_acc: 0.8946 - digit4_acc: 0.8671 - val_loss: 2.1983 - val_digit1_loss: 0.6581 - val_digit2_loss: 0.3574 - val_digit3_loss: 0.3164 - val_digit4_loss: 0.8664 - val_digit1_acc: 0.7833 - val_digit2_acc: 0.8900 - val_digit3_acc: 0.8833 - val_digit4_acc: 0.7333\n",
      "Epoch 5/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.9065 - digit1_loss: 0.2185 - digit2_loss: 0.2275 - digit3_loss: 0.2297 - digit4_loss: 0.2307 - digit1_acc: 0.9285 - digit2_acc: 0.9300 - digit3_acc: 0.9230 - digit4_acc: 0.9270 - val_loss: 1.8963 - val_digit1_loss: 0.5017 - val_digit2_loss: 0.4085 - val_digit3_loss: 0.2715 - val_digit4_loss: 0.7146 - val_digit1_acc: 0.8200 - val_digit2_acc: 0.8633 - val_digit3_acc: 0.9433 - val_digit4_acc: 0.7533\n",
      "Epoch 6/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.5813 - digit1_loss: 0.1320 - digit2_loss: 0.1709 - digit3_loss: 0.1330 - digit4_loss: 0.1454 - digit1_acc: 0.9575 - digit2_acc: 0.9470 - digit3_acc: 0.9600 - digit4_acc: 0.9520 - val_loss: 1.5071 - val_digit1_loss: 0.4548 - val_digit2_loss: 0.2275 - val_digit3_loss: 0.2319 - val_digit4_loss: 0.5930 - val_digit1_acc: 0.8500 - val_digit2_acc: 0.9333 - val_digit3_acc: 0.9500 - val_digit4_acc: 0.8100\n",
      "Epoch 7/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.3489 - digit1_loss: 0.0862 - digit2_loss: 0.1047 - digit3_loss: 0.0753 - digit4_loss: 0.0827 - digit1_acc: 0.9735 - digit2_acc: 0.9645 - digit3_acc: 0.9790 - digit4_acc: 0.9765 - val_loss: 1.4102 - val_digit1_loss: 0.4403 - val_digit2_loss: 0.2333 - val_digit3_loss: 0.2262 - val_digit4_loss: 0.5103 - val_digit1_acc: 0.8500 - val_digit2_acc: 0.9367 - val_digit3_acc: 0.9367 - val_digit4_acc: 0.8367\n",
      "Epoch 8/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.2670 - digit1_loss: 0.0716 - digit2_loss: 0.0672 - digit3_loss: 0.0584 - digit4_loss: 0.0699 - digit1_acc: 0.9765 - digit2_acc: 0.9790 - digit3_acc: 0.9840 - digit4_acc: 0.9775 - val_loss: 1.2936 - val_digit1_loss: 0.3534 - val_digit2_loss: 0.2221 - val_digit3_loss: 0.2065 - val_digit4_loss: 0.5115 - val_digit1_acc: 0.8533 - val_digit2_acc: 0.9367 - val_digit3_acc: 0.9533 - val_digit4_acc: 0.8533\n",
      "Epoch 9/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.1989 - digit1_loss: 0.0500 - digit2_loss: 0.0540 - digit3_loss: 0.0440 - digit4_loss: 0.0508 - digit1_acc: 0.9835 - digit2_acc: 0.9815 - digit3_acc: 0.9865 - digit4_acc: 0.9885 - val_loss: 1.3022 - val_digit1_loss: 0.3864 - val_digit2_loss: 0.2150 - val_digit3_loss: 0.1879 - val_digit4_loss: 0.5130 - val_digit1_acc: 0.8733 - val_digit2_acc: 0.9433 - val_digit3_acc: 0.9467 - val_digit4_acc: 0.8667\n",
      "Epoch 10/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.1659 - digit1_loss: 0.0470 - digit2_loss: 0.0523 - digit3_loss: 0.0267 - digit4_loss: 0.0399 - digit1_acc: 0.9840 - digit2_acc: 0.9835 - digit3_acc: 0.9920 - digit4_acc: 0.9885 - val_loss: 1.1319 - val_digit1_loss: 0.3529 - val_digit2_loss: 0.1862 - val_digit3_loss: 0.1678 - val_digit4_loss: 0.4250 - val_digit1_acc: 0.8733 - val_digit2_acc: 0.9500 - val_digit3_acc: 0.9600 - val_digit4_acc: 0.8733\n",
      "Epoch 11/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.1099 - digit1_loss: 0.0262 - digit2_loss: 0.0302 - digit3_loss: 0.0210 - digit4_loss: 0.0325 - digit1_acc: 0.9940 - digit2_acc: 0.9920 - digit3_acc: 0.9945 - digit4_acc: 0.9905 - val_loss: 0.9913 - val_digit1_loss: 0.2667 - val_digit2_loss: 0.1637 - val_digit3_loss: 0.1654 - val_digit4_loss: 0.3954 - val_digit1_acc: 0.9000 - val_digit2_acc: 0.9467 - val_digit3_acc: 0.9600 - val_digit4_acc: 0.8867\n",
      "Epoch 12/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0923 - digit1_loss: 0.0227 - digit2_loss: 0.0200 - digit3_loss: 0.0232 - digit4_loss: 0.0265 - digit1_acc: 0.9940 - digit2_acc: 0.9930 - digit3_acc: 0.9955 - digit4_acc: 0.9910 - val_loss: 0.9997 - val_digit1_loss: 0.3228 - val_digit2_loss: 0.1420 - val_digit3_loss: 0.1430 - val_digit4_loss: 0.3920 - val_digit1_acc: 0.8800 - val_digit2_acc: 0.9633 - val_digit3_acc: 0.9667 - val_digit4_acc: 0.8800\n",
      "Epoch 13/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0952 - digit1_loss: 0.0239 - digit2_loss: 0.0272 - digit3_loss: 0.0187 - digit4_loss: 0.0254 - digit1_acc: 0.9940 - digit2_acc: 0.9900 - digit3_acc: 0.9965 - digit4_acc: 0.9920 - val_loss: 0.9587 - val_digit1_loss: 0.2847 - val_digit2_loss: 0.1477 - val_digit3_loss: 0.1472 - val_digit4_loss: 0.3791 - val_digit1_acc: 0.8967 - val_digit2_acc: 0.9600 - val_digit3_acc: 0.9633 - val_digit4_acc: 0.8967\n",
      "Epoch 14/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0613 - digit1_loss: 0.0170 - digit2_loss: 0.0175 - digit3_loss: 0.0121 - digit4_loss: 0.0147 - digit1_acc: 0.9950 - digit2_acc: 0.9945 - digit3_acc: 0.9975 - digit4_acc: 0.9970 - val_loss: 0.8057 - val_digit1_loss: 0.2267 - val_digit2_loss: 0.1129 - val_digit3_loss: 0.1309 - val_digit4_loss: 0.3352 - val_digit1_acc: 0.9133 - val_digit2_acc: 0.9633 - val_digit3_acc: 0.9733 - val_digit4_acc: 0.8867\n",
      "Epoch 15/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0597 - digit1_loss: 0.0157 - digit2_loss: 0.0168 - digit3_loss: 0.0107 - digit4_loss: 0.0165 - digit1_acc: 0.9945 - digit2_acc: 0.9955 - digit3_acc: 0.9970 - digit4_acc: 0.9965 - val_loss: 0.9131 - val_digit1_loss: 0.2883 - val_digit2_loss: 0.1303 - val_digit3_loss: 0.1592 - val_digit4_loss: 0.3352 - val_digit1_acc: 0.9000 - val_digit2_acc: 0.9667 - val_digit3_acc: 0.9667 - val_digit4_acc: 0.9000\n",
      "Epoch 16/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0629 - digit1_loss: 0.0197 - digit2_loss: 0.0187 - digit3_loss: 0.0114 - digit4_loss: 0.0130 - digit1_acc: 0.9935 - digit2_acc: 0.9935 - digit3_acc: 0.9975 - digit4_acc: 0.9975 - val_loss: 0.8003 - val_digit1_loss: 0.1998 - val_digit2_loss: 0.1325 - val_digit3_loss: 0.1174 - val_digit4_loss: 0.3506 - val_digit1_acc: 0.9200 - val_digit2_acc: 0.9633 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9067\n",
      "Epoch 17/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0617 - digit1_loss: 0.0245 - digit2_loss: 0.0157 - digit3_loss: 0.0099 - digit4_loss: 0.0115 - digit1_acc: 0.9910 - digit2_acc: 0.9950 - digit3_acc: 0.9980 - digit4_acc: 0.9965 - val_loss: 0.8485 - val_digit1_loss: 0.2847 - val_digit2_loss: 0.1542 - val_digit3_loss: 0.1239 - val_digit4_loss: 0.2857 - val_digit1_acc: 0.9067 - val_digit2_acc: 0.9667 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9100\n",
      "Epoch 18/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0367 - digit1_loss: 0.0055 - digit2_loss: 0.0118 - digit3_loss: 0.0073 - digit4_loss: 0.0120 - digit1_acc: 0.9995 - digit2_acc: 0.9970 - digit3_acc: 0.9990 - digit4_acc: 0.9965 - val_loss: 0.8263 - val_digit1_loss: 0.2132 - val_digit2_loss: 0.1578 - val_digit3_loss: 0.1157 - val_digit4_loss: 0.3396 - val_digit1_acc: 0.9167 - val_digit2_acc: 0.9667 - val_digit3_acc: 0.9633 - val_digit4_acc: 0.9100\n",
      "Epoch 19/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0354 - digit1_loss: 0.0088 - digit2_loss: 0.0108 - digit3_loss: 0.0082 - digit4_loss: 0.0077 - digit1_acc: 0.9975 - digit2_acc: 0.9965 - digit3_acc: 0.9965 - digit4_acc: 0.9980 - val_loss: 1.0274 - val_digit1_loss: 0.3833 - val_digit2_loss: 0.1476 - val_digit3_loss: 0.1340 - val_digit4_loss: 0.3625 - val_digit1_acc: 0.8833 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9667 - val_digit4_acc: 0.9000\n",
      "Epoch 20/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0304 - digit1_loss: 0.0082 - digit2_loss: 0.0080 - digit3_loss: 0.0081 - digit4_loss: 0.0061 - digit1_acc: 0.9985 - digit2_acc: 0.9990 - digit3_acc: 0.9980 - digit4_acc: 0.9990 - val_loss: 0.8033 - val_digit1_loss: 0.2272 - val_digit2_loss: 0.1251 - val_digit3_loss: 0.1071 - val_digit4_loss: 0.3439 - val_digit1_acc: 0.9133 - val_digit2_acc: 0.9633 - val_digit3_acc: 0.9667 - val_digit4_acc: 0.8967\n",
      "Epoch 21/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0300 - digit1_loss: 0.0094 - digit2_loss: 0.0098 - digit3_loss: 0.0076 - digit4_loss: 0.0031 - digit1_acc: 0.9975 - digit2_acc: 0.9980 - digit3_acc: 0.9980 - digit4_acc: 1.0000 - val_loss: 0.8958 - val_digit1_loss: 0.3032 - val_digit2_loss: 0.1345 - val_digit3_loss: 0.1318 - val_digit4_loss: 0.3262 - val_digit1_acc: 0.8867 - val_digit2_acc: 0.9667 - val_digit3_acc: 0.9700 - val_digit4_acc: 0.9067\n",
      "Epoch 22/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0238 - digit1_loss: 0.0087 - digit2_loss: 0.0052 - digit3_loss: 0.0051 - digit4_loss: 0.0048 - digit1_acc: 0.9965 - digit2_acc: 0.9985 - digit3_acc: 0.9985 - digit4_acc: 0.9990 - val_loss: 0.9284 - val_digit1_loss: 0.2902 - val_digit2_loss: 0.1358 - val_digit3_loss: 0.1434 - val_digit4_loss: 0.3590 - val_digit1_acc: 0.8967 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9133\n",
      "Epoch 23/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0175 - digit1_loss: 0.0033 - digit2_loss: 0.0087 - digit3_loss: 0.0024 - digit4_loss: 0.0030 - digit1_acc: 0.9990 - digit2_acc: 0.9970 - digit3_acc: 1.0000 - digit4_acc: 0.9995 - val_loss: 0.7667 - val_digit1_loss: 0.2165 - val_digit2_loss: 0.1001 - val_digit3_loss: 0.1160 - val_digit4_loss: 0.3341 - val_digit1_acc: 0.9200 - val_digit2_acc: 0.9800 - val_digit3_acc: 0.9733 - val_digit4_acc: 0.9100\n",
      "Epoch 24/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0188 - digit1_loss: 0.0043 - digit2_loss: 0.0059 - digit3_loss: 0.0042 - digit4_loss: 0.0044 - digit1_acc: 0.9985 - digit2_acc: 0.9975 - digit3_acc: 0.9980 - digit4_acc: 0.9980 - val_loss: 0.7553 - val_digit1_loss: 0.1964 - val_digit2_loss: 0.1025 - val_digit3_loss: 0.1269 - val_digit4_loss: 0.3294 - val_digit1_acc: 0.9267 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9133\n",
      "Epoch 25/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0166 - digit1_loss: 0.0058 - digit2_loss: 0.0045 - digit3_loss: 0.0036 - digit4_loss: 0.0027 - digit1_acc: 0.9985 - digit2_acc: 0.9990 - digit3_acc: 0.9995 - digit4_acc: 1.0000 - val_loss: 0.8408 - val_digit1_loss: 0.1928 - val_digit2_loss: 0.1224 - val_digit3_loss: 0.1493 - val_digit4_loss: 0.3763 - val_digit1_acc: 0.9200 - val_digit2_acc: 0.9667 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9033\n",
      "Epoch 26/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0162 - digit1_loss: 0.0038 - digit2_loss: 0.0038 - digit3_loss: 0.0050 - digit4_loss: 0.0036 - digit1_acc: 0.9985 - digit2_acc: 0.9990 - digit3_acc: 0.9985 - digit4_acc: 0.9995 - val_loss: 0.8874 - val_digit1_loss: 0.2279 - val_digit2_loss: 0.1411 - val_digit3_loss: 0.1548 - val_digit4_loss: 0.3637 - val_digit1_acc: 0.9300 - val_digit2_acc: 0.9600 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9133\n",
      "Epoch 27/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0231 - digit1_loss: 0.0078 - digit2_loss: 0.0069 - digit3_loss: 0.0044 - digit4_loss: 0.0040 - digit1_acc: 0.9980 - digit2_acc: 0.9980 - digit3_acc: 0.9990 - digit4_acc: 0.9995 - val_loss: 0.8396 - val_digit1_loss: 0.2329 - val_digit2_loss: 0.1194 - val_digit3_loss: 0.1224 - val_digit4_loss: 0.3650 - val_digit1_acc: 0.9400 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.8967\n",
      "Epoch 28/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0175 - digit1_loss: 0.0046 - digit2_loss: 0.0030 - digit3_loss: 0.0064 - digit4_loss: 0.0035 - digit1_acc: 0.9980 - digit2_acc: 0.9995 - digit3_acc: 0.9975 - digit4_acc: 0.9990 - val_loss: 0.8406 - val_digit1_loss: 0.2499 - val_digit2_loss: 0.1158 - val_digit3_loss: 0.1227 - val_digit4_loss: 0.3522 - val_digit1_acc: 0.9300 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9133\n",
      "Epoch 29/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0162 - digit1_loss: 0.0032 - digit2_loss: 0.0073 - digit3_loss: 0.0035 - digit4_loss: 0.0021 - digit1_acc: 0.9995 - digit2_acc: 0.9980 - digit3_acc: 0.9995 - digit4_acc: 1.0000 - val_loss: 0.9055 - val_digit1_loss: 0.3492 - val_digit2_loss: 0.0946 - val_digit3_loss: 0.1314 - val_digit4_loss: 0.3303 - val_digit1_acc: 0.9100 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9700 - val_digit4_acc: 0.9200\n",
      "Epoch 30/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0158 - digit1_loss: 0.0036 - digit2_loss: 0.0040 - digit3_loss: 0.0026 - digit4_loss: 0.0056 - digit1_acc: 0.9995 - digit2_acc: 0.9990 - digit3_acc: 0.9990 - digit4_acc: 0.9990 - val_loss: 0.8096 - val_digit1_loss: 0.2813 - val_digit2_loss: 0.1064 - val_digit3_loss: 0.1265 - val_digit4_loss: 0.2954 - val_digit1_acc: 0.9300 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9300\n",
      "Epoch 31/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0138 - digit1_loss: 0.0023 - digit2_loss: 0.0052 - digit3_loss: 0.0032 - digit4_loss: 0.0032 - digit1_acc: 0.9995 - digit2_acc: 0.9985 - digit3_acc: 0.9995 - digit4_acc: 0.9990 - val_loss: 0.8045 - val_digit1_loss: 0.3032 - val_digit2_loss: 0.0830 - val_digit3_loss: 0.1121 - val_digit4_loss: 0.3062 - val_digit1_acc: 0.9133 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9333\n",
      "Epoch 32/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0157 - digit1_loss: 0.0047 - digit2_loss: 0.0015 - digit3_loss: 0.0064 - digit4_loss: 0.0032 - digit1_acc: 0.9985 - digit2_acc: 1.0000 - digit3_acc: 0.9985 - digit4_acc: 0.9990 - val_loss: 0.8436 - val_digit1_loss: 0.2744 - val_digit2_loss: 0.1053 - val_digit3_loss: 0.1168 - val_digit4_loss: 0.3470 - val_digit1_acc: 0.9133 - val_digit2_acc: 0.9800 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9167\n",
      "Epoch 33/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0095 - digit1_loss: 0.0033 - digit2_loss: 0.0024 - digit3_loss: 0.0022 - digit4_loss: 0.0016 - digit1_acc: 0.9990 - digit2_acc: 0.9995 - digit3_acc: 0.9995 - digit4_acc: 0.9995 - val_loss: 0.7600 - val_digit1_loss: 0.2047 - val_digit2_loss: 0.1180 - val_digit3_loss: 0.1068 - val_digit4_loss: 0.3305 - val_digit1_acc: 0.9400 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9100\n",
      "Epoch 34/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0086 - digit1_loss: 0.0029 - digit2_loss: 0.0033 - digit3_loss: 8.4328e-04 - digit4_loss: 0.0015 - digit1_acc: 0.9990 - digit2_acc: 0.9995 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.9837 - val_digit1_loss: 0.3175 - val_digit2_loss: 0.1285 - val_digit3_loss: 0.1514 - val_digit4_loss: 0.3862 - val_digit1_acc: 0.9100 - val_digit2_acc: 0.9667 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9133\n",
      "Epoch 35/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0085 - digit1_loss: 0.0016 - digit2_loss: 0.0025 - digit3_loss: 0.0028 - digit4_loss: 0.0015 - digit1_acc: 0.9995 - digit2_acc: 0.9990 - digit3_acc: 0.9985 - digit4_acc: 1.0000 - val_loss: 0.8670 - val_digit1_loss: 0.2544 - val_digit2_loss: 0.1143 - val_digit3_loss: 0.1235 - val_digit4_loss: 0.3748 - val_digit1_acc: 0.9233 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9100\n",
      "Epoch 36/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0087 - digit1_loss: 0.0018 - digit2_loss: 0.0027 - digit3_loss: 0.0018 - digit4_loss: 0.0024 - digit1_acc: 1.0000 - digit2_acc: 0.9995 - digit3_acc: 0.9995 - digit4_acc: 0.9995 - val_loss: 0.9342 - val_digit1_loss: 0.3228 - val_digit2_loss: 0.1405 - val_digit3_loss: 0.1477 - val_digit4_loss: 0.3233 - val_digit1_acc: 0.9267 - val_digit2_acc: 0.9667 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9267\n",
      "Epoch 37/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0054 - digit1_loss: 0.0011 - digit2_loss: 0.0011 - digit3_loss: 0.0014 - digit4_loss: 0.0017 - digit1_acc: 0.9995 - digit2_acc: 1.0000 - digit3_acc: 0.9995 - digit4_acc: 1.0000 - val_loss: 0.7699 - val_digit1_loss: 0.2466 - val_digit2_loss: 0.1109 - val_digit3_loss: 0.1311 - val_digit4_loss: 0.2813 - val_digit1_acc: 0.9333 - val_digit2_acc: 0.9667 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9333\n",
      "Epoch 38/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0103 - digit1_loss: 0.0012 - digit2_loss: 0.0045 - digit3_loss: 0.0024 - digit4_loss: 0.0022 - digit1_acc: 1.0000 - digit2_acc: 0.9985 - digit3_acc: 0.9990 - digit4_acc: 0.9985 - val_loss: 0.7261 - val_digit1_loss: 0.2076 - val_digit2_loss: 0.1023 - val_digit3_loss: 0.0982 - val_digit4_loss: 0.3180 - val_digit1_acc: 0.9500 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9300\n",
      "Epoch 39/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0098 - digit1_loss: 0.0033 - digit2_loss: 0.0016 - digit3_loss: 0.0041 - digit4_loss: 7.2170e-04 - digit1_acc: 0.9990 - digit2_acc: 0.9995 - digit3_acc: 0.9985 - digit4_acc: 1.0000 - val_loss: 0.8512 - val_digit1_loss: 0.2662 - val_digit2_loss: 0.1219 - val_digit3_loss: 0.1641 - val_digit4_loss: 0.2990 - val_digit1_acc: 0.9233 - val_digit2_acc: 0.9633 - val_digit3_acc: 0.9733 - val_digit4_acc: 0.9400\n",
      "Epoch 40/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0074 - digit1_loss: 0.0026 - digit2_loss: 0.0013 - digit3_loss: 0.0020 - digit4_loss: 0.0014 - digit1_acc: 0.9990 - digit2_acc: 1.0000 - digit3_acc: 0.9995 - digit4_acc: 0.9995 - val_loss: 0.6686 - val_digit1_loss: 0.1805 - val_digit2_loss: 0.0892 - val_digit3_loss: 0.1136 - val_digit4_loss: 0.2853 - val_digit1_acc: 0.9500 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9300\n",
      "Epoch 41/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0067 - digit1_loss: 0.0017 - digit2_loss: 0.0022 - digit3_loss: 0.0021 - digit4_loss: 6.8982e-04 - digit1_acc: 0.9995 - digit2_acc: 0.9990 - digit3_acc: 0.9995 - digit4_acc: 1.0000 - val_loss: 0.7551 - val_digit1_loss: 0.2973 - val_digit2_loss: 0.0690 - val_digit3_loss: 0.1047 - val_digit4_loss: 0.2843 - val_digit1_acc: 0.9200 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9300\n",
      "Epoch 42/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0080 - digit1_loss: 0.0030 - digit2_loss: 0.0027 - digit3_loss: 6.2205e-04 - digit4_loss: 0.0017 - digit1_acc: 0.9990 - digit2_acc: 0.9985 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7499 - val_digit1_loss: 0.2386 - val_digit2_loss: 0.0895 - val_digit3_loss: 0.1149 - val_digit4_loss: 0.3068 - val_digit1_acc: 0.9233 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9333\n",
      "Epoch 43/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0066 - digit1_loss: 0.0036 - digit2_loss: 0.0014 - digit3_loss: 5.2316e-04 - digit4_loss: 0.0011 - digit1_acc: 0.9985 - digit2_acc: 0.9995 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7884 - val_digit1_loss: 0.2632 - val_digit2_loss: 0.0888 - val_digit3_loss: 0.1213 - val_digit4_loss: 0.3151 - val_digit1_acc: 0.9267 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9300\n",
      "Epoch 44/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0092 - digit1_loss: 0.0015 - digit2_loss: 0.0031 - digit3_loss: 8.7456e-04 - digit4_loss: 0.0037 - digit1_acc: 0.9995 - digit2_acc: 0.9985 - digit3_acc: 1.0000 - digit4_acc: 0.9995 - val_loss: 0.7433 - val_digit1_loss: 0.2538 - val_digit2_loss: 0.0856 - val_digit3_loss: 0.1084 - val_digit4_loss: 0.2954 - val_digit1_acc: 0.9333 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9333\n",
      "Epoch 45/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0036 - digit1_loss: 0.0016 - digit2_loss: 8.2746e-04 - digit3_loss: 5.5945e-04 - digit4_loss: 5.7439e-04 - digit1_acc: 0.9990 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6929 - val_digit1_loss: 0.2107 - val_digit2_loss: 0.0715 - val_digit3_loss: 0.1090 - val_digit4_loss: 0.3017 - val_digit1_acc: 0.9433 - val_digit2_acc: 0.9867 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9333\n",
      "Epoch 46/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0071 - digit1_loss: 0.0016 - digit2_loss: 0.0018 - digit3_loss: 3.3675e-04 - digit4_loss: 0.0033 - digit1_acc: 0.9995 - digit2_acc: 0.9995 - digit3_acc: 1.0000 - digit4_acc: 0.9995 - val_loss: 0.7143 - val_digit1_loss: 0.2166 - val_digit2_loss: 0.0803 - val_digit3_loss: 0.1109 - val_digit4_loss: 0.3065 - val_digit1_acc: 0.9467 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9267\n",
      "Epoch 47/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0031 - digit1_loss: 5.9426e-04 - digit2_loss: 0.0011 - digit3_loss: 3.3654e-04 - digit4_loss: 0.0010 - digit1_acc: 1.0000 - digit2_acc: 0.9995 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7083 - val_digit1_loss: 0.2037 - val_digit2_loss: 0.0784 - val_digit3_loss: 0.1433 - val_digit4_loss: 0.2830 - val_digit1_acc: 0.9433 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9733 - val_digit4_acc: 0.9367\n",
      "Epoch 48/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0029 - digit1_loss: 0.0013 - digit2_loss: 2.8893e-04 - digit3_loss: 5.9058e-04 - digit4_loss: 7.7069e-04 - digit1_acc: 0.9995 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 0.9995 - val_loss: 0.6993 - val_digit1_loss: 0.2013 - val_digit2_loss: 0.0786 - val_digit3_loss: 0.1335 - val_digit4_loss: 0.2859 - val_digit1_acc: 0.9400 - val_digit2_acc: 0.9833 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9367\n",
      "Epoch 49/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0042 - digit1_loss: 6.7094e-04 - digit2_loss: 0.0018 - digit3_loss: 4.3223e-04 - digit4_loss: 0.0013 - digit1_acc: 1.0000 - digit2_acc: 0.9990 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6708 - val_digit1_loss: 0.2015 - val_digit2_loss: 0.0897 - val_digit3_loss: 0.0986 - val_digit4_loss: 0.2810 - val_digit1_acc: 0.9333 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9400\n",
      "Epoch 50/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0028 - digit1_loss: 3.3605e-04 - digit2_loss: 9.1889e-04 - digit3_loss: 2.9108e-04 - digit4_loss: 0.0012 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 0.9995 - val_loss: 0.7274 - val_digit1_loss: 0.2254 - val_digit2_loss: 0.0979 - val_digit3_loss: 0.1377 - val_digit4_loss: 0.2664 - val_digit1_acc: 0.9333 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9733 - val_digit4_acc: 0.9433\n",
      "Epoch 51/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0071 - digit1_loss: 0.0038 - digit2_loss: 0.0022 - digit3_loss: 2.7907e-04 - digit4_loss: 8.5057e-04 - digit1_acc: 0.9990 - digit2_acc: 0.9990 - digit3_acc: 1.0000 - digit4_acc: 0.9995 - val_loss: 0.8066 - val_digit1_loss: 0.2557 - val_digit2_loss: 0.0995 - val_digit3_loss: 0.1417 - val_digit4_loss: 0.3097 - val_digit1_acc: 0.9300 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0096 - digit1_loss: 0.0030 - digit2_loss: 0.0031 - digit3_loss: 0.0022 - digit4_loss: 0.0013 - digit1_acc: 0.9990 - digit2_acc: 0.9995 - digit3_acc: 0.9990 - digit4_acc: 0.9995 - val_loss: 0.7273 - val_digit1_loss: 0.2043 - val_digit2_loss: 0.0919 - val_digit3_loss: 0.1337 - val_digit4_loss: 0.2974 - val_digit1_acc: 0.9467 - val_digit2_acc: 0.9833 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9333\n",
      "Epoch 53/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0048 - digit1_loss: 0.0016 - digit2_loss: 0.0017 - digit3_loss: 9.4525e-04 - digit4_loss: 4.5620e-04 - digit1_acc: 0.9995 - digit2_acc: 0.9995 - digit3_acc: 0.9995 - digit4_acc: 1.0000 - val_loss: 0.7629 - val_digit1_loss: 0.2853 - val_digit2_loss: 0.0833 - val_digit3_loss: 0.0792 - val_digit4_loss: 0.3151 - val_digit1_acc: 0.9267 - val_digit2_acc: 0.9800 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9233\n",
      "Epoch 54/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0035 - digit1_loss: 1.7251e-04 - digit2_loss: 0.0026 - digit3_loss: 3.9471e-04 - digit4_loss: 3.3978e-04 - digit1_acc: 1.0000 - digit2_acc: 0.9995 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7920 - val_digit1_loss: 0.3023 - val_digit2_loss: 0.1067 - val_digit3_loss: 0.0838 - val_digit4_loss: 0.2991 - val_digit1_acc: 0.9267 - val_digit2_acc: 0.9800 - val_digit3_acc: 0.9900 - val_digit4_acc: 0.9367\n",
      "Epoch 55/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0053 - digit1_loss: 0.0018 - digit2_loss: 0.0025 - digit3_loss: 5.5789e-04 - digit4_loss: 4.1417e-04 - digit1_acc: 0.9995 - digit2_acc: 0.9990 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6677 - val_digit1_loss: 0.2307 - val_digit2_loss: 0.1109 - val_digit3_loss: 0.0825 - val_digit4_loss: 0.2436 - val_digit1_acc: 0.9367 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9400\n",
      "Epoch 56/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0050 - digit1_loss: 0.0016 - digit2_loss: 3.9678e-04 - digit3_loss: 9.6006e-04 - digit4_loss: 0.0021 - digit1_acc: 0.9990 - digit2_acc: 1.0000 - digit3_acc: 0.9995 - digit4_acc: 0.9990 - val_loss: 0.6284 - val_digit1_loss: 0.2075 - val_digit2_loss: 0.0941 - val_digit3_loss: 0.0926 - val_digit4_loss: 0.2342 - val_digit1_acc: 0.9333 - val_digit2_acc: 0.9833 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9500\n",
      "Epoch 57/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0047 - digit1_loss: 0.0028 - digit2_loss: 9.7125e-04 - digit3_loss: 1.5424e-04 - digit4_loss: 7.7007e-04 - digit1_acc: 0.9990 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7076 - val_digit1_loss: 0.2818 - val_digit2_loss: 0.0955 - val_digit3_loss: 0.1032 - val_digit4_loss: 0.2271 - val_digit1_acc: 0.9300 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9533\n",
      "Epoch 58/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0026 - digit1_loss: 5.6626e-04 - digit2_loss: 6.3942e-04 - digit3_loss: 3.1715e-04 - digit4_loss: 0.0011 - digit1_acc: 0.9995 - digit2_acc: 0.9995 - digit3_acc: 1.0000 - digit4_acc: 0.9995 - val_loss: 0.6830 - val_digit1_loss: 0.2381 - val_digit2_loss: 0.0732 - val_digit3_loss: 0.1078 - val_digit4_loss: 0.2640 - val_digit1_acc: 0.9367 - val_digit2_acc: 0.9833 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9367\n",
      "Epoch 59/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0059 - digit1_loss: 0.0013 - digit2_loss: 0.0017 - digit3_loss: 1.6870e-04 - digit4_loss: 0.0028 - digit1_acc: 0.9995 - digit2_acc: 0.9990 - digit3_acc: 1.0000 - digit4_acc: 0.9985 - val_loss: 0.6656 - val_digit1_loss: 0.2304 - val_digit2_loss: 0.0745 - val_digit3_loss: 0.1108 - val_digit4_loss: 0.2500 - val_digit1_acc: 0.9433 - val_digit2_acc: 0.9700 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9333\n",
      "Epoch 60/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0012 - digit1_loss: 4.6611e-04 - digit2_loss: 3.4050e-04 - digit3_loss: 2.5195e-04 - digit4_loss: 1.5517e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6890 - val_digit1_loss: 0.2184 - val_digit2_loss: 0.0641 - val_digit3_loss: 0.1205 - val_digit4_loss: 0.2860 - val_digit1_acc: 0.9367 - val_digit2_acc: 0.9833 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9233\n",
      "Epoch 61/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0046 - digit1_loss: 0.0040 - digit2_loss: 2.1884e-04 - digit3_loss: 2.3689e-04 - digit4_loss: 1.8439e-04 - digit1_acc: 0.9990 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6158 - val_digit1_loss: 0.1979 - val_digit2_loss: 0.0772 - val_digit3_loss: 0.0922 - val_digit4_loss: 0.2486 - val_digit1_acc: 0.9500 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9467\n",
      "Epoch 62/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0019 - digit1_loss: 5.6911e-04 - digit2_loss: 8.0416e-04 - digit3_loss: 1.9032e-04 - digit4_loss: 3.7645e-04 - digit1_acc: 0.9995 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7680 - val_digit1_loss: 0.2571 - val_digit2_loss: 0.1051 - val_digit3_loss: 0.1328 - val_digit4_loss: 0.2730 - val_digit1_acc: 0.9400 - val_digit2_acc: 0.9633 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9367\n",
      "Epoch 63/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0027 - digit1_loss: 0.0017 - digit2_loss: 3.1710e-04 - digit3_loss: 4.3715e-04 - digit4_loss: 2.2535e-04 - digit1_acc: 0.9995 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7184 - val_digit1_loss: 0.2650 - val_digit2_loss: 0.0852 - val_digit3_loss: 0.1405 - val_digit4_loss: 0.2276 - val_digit1_acc: 0.9400 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9433\n",
      "Epoch 64/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0046 - digit1_loss: 0.0026 - digit2_loss: 3.3279e-04 - digit3_loss: 6.9958e-04 - digit4_loss: 9.0454e-04 - digit1_acc: 0.9990 - digit2_acc: 1.0000 - digit3_acc: 0.9995 - digit4_acc: 0.9995 - val_loss: 0.6875 - val_digit1_loss: 0.2047 - val_digit2_loss: 0.0955 - val_digit3_loss: 0.1460 - val_digit4_loss: 0.2413 - val_digit1_acc: 0.9500 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9333\n",
      "Epoch 65/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0036 - digit1_loss: 0.0011 - digit2_loss: 0.0020 - digit3_loss: 2.1375e-04 - digit4_loss: 2.6396e-04 - digit1_acc: 0.9995 - digit2_acc: 0.9995 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7414 - val_digit1_loss: 0.2229 - val_digit2_loss: 0.1000 - val_digit3_loss: 0.1549 - val_digit4_loss: 0.2636 - val_digit1_acc: 0.9433 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9300\n",
      "Epoch 66/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0049 - digit1_loss: 1.8673e-04 - digit2_loss: 1.6970e-04 - digit3_loss: 0.0031 - digit4_loss: 0.0014 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 0.9990 - digit4_acc: 0.9995 - val_loss: 0.7074 - val_digit1_loss: 0.2575 - val_digit2_loss: 0.0884 - val_digit3_loss: 0.1420 - val_digit4_loss: 0.2195 - val_digit1_acc: 0.9400 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9500\n",
      "Epoch 67/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0012 - digit1_loss: 2.8176e-04 - digit2_loss: 3.8452e-04 - digit3_loss: 4.0547e-04 - digit4_loss: 1.4426e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7854 - val_digit1_loss: 0.2732 - val_digit2_loss: 0.0740 - val_digit3_loss: 0.1672 - val_digit4_loss: 0.2710 - val_digit1_acc: 0.9400 - val_digit2_acc: 0.9833 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9500\n",
      "Epoch 68/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0013 - digit1_loss: 3.9961e-04 - digit2_loss: 4.2731e-04 - digit3_loss: 1.3508e-04 - digit4_loss: 3.1936e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7225 - val_digit1_loss: 0.2482 - val_digit2_loss: 0.0745 - val_digit3_loss: 0.1249 - val_digit4_loss: 0.2749 - val_digit1_acc: 0.9433 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0021 - digit1_loss: 6.3021e-04 - digit2_loss: 7.5659e-04 - digit3_loss: 5.8697e-04 - digit4_loss: 1.4358e-04 - digit1_acc: 1.0000 - digit2_acc: 0.9995 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7335 - val_digit1_loss: 0.2467 - val_digit2_loss: 0.0822 - val_digit3_loss: 0.1438 - val_digit4_loss: 0.2608 - val_digit1_acc: 0.9367 - val_digit2_acc: 0.9800 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9433\n",
      "Epoch 70/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 9.6322e-04 - digit1_loss: 2.9091e-04 - digit2_loss: 3.7827e-04 - digit3_loss: 1.9111e-04 - digit4_loss: 1.0292e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7375 - val_digit1_loss: 0.2568 - val_digit2_loss: 0.0952 - val_digit3_loss: 0.1348 - val_digit4_loss: 0.2507 - val_digit1_acc: 0.9333 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9367\n",
      "Epoch 71/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0010 - digit1_loss: 1.8449e-04 - digit2_loss: 4.3940e-04 - digit3_loss: 1.4300e-04 - digit4_loss: 2.4067e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.8694 - val_digit1_loss: 0.3412 - val_digit2_loss: 0.1026 - val_digit3_loss: 0.1461 - val_digit4_loss: 0.2796 - val_digit1_acc: 0.9300 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9400\n",
      "Epoch 72/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0015 - digit1_loss: 1.8887e-04 - digit2_loss: 7.6457e-04 - digit3_loss: 2.4064e-04 - digit4_loss: 2.9514e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.8451 - val_digit1_loss: 0.3403 - val_digit2_loss: 0.0972 - val_digit3_loss: 0.1230 - val_digit4_loss: 0.2845 - val_digit1_acc: 0.9300 - val_digit2_acc: 0.9700 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9467\n",
      "Epoch 73/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0019 - digit1_loss: 9.3257e-04 - digit2_loss: 1.1231e-04 - digit3_loss: 1.0087e-04 - digit4_loss: 7.0497e-04 - digit1_acc: 0.9995 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 0.9995 - val_loss: 0.7704 - val_digit1_loss: 0.2556 - val_digit2_loss: 0.0882 - val_digit3_loss: 0.1113 - val_digit4_loss: 0.3154 - val_digit1_acc: 0.9467 - val_digit2_acc: 0.9800 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9367\n",
      "Epoch 74/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0025 - digit1_loss: 3.4248e-04 - digit2_loss: 2.8609e-04 - digit3_loss: 0.0014 - digit4_loss: 4.9671e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 0.9995 - digit4_acc: 0.9995 - val_loss: 0.7390 - val_digit1_loss: 0.2459 - val_digit2_loss: 0.0794 - val_digit3_loss: 0.1122 - val_digit4_loss: 0.3014 - val_digit1_acc: 0.9467 - val_digit2_acc: 0.9833 - val_digit3_acc: 0.9900 - val_digit4_acc: 0.9333\n",
      "Epoch 75/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0049 - digit1_loss: 1.4723e-04 - digit2_loss: 0.0040 - digit3_loss: 8.7077e-05 - digit4_loss: 5.9713e-04 - digit1_acc: 1.0000 - digit2_acc: 0.9995 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7378 - val_digit1_loss: 0.2750 - val_digit2_loss: 0.0858 - val_digit3_loss: 0.1513 - val_digit4_loss: 0.2257 - val_digit1_acc: 0.9467 - val_digit2_acc: 0.9833 - val_digit3_acc: 0.9733 - val_digit4_acc: 0.9567\n",
      "Epoch 76/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0022 - digit1_loss: 0.0017 - digit2_loss: 1.5267e-04 - digit3_loss: 6.0413e-05 - digit4_loss: 2.9097e-04 - digit1_acc: 0.9995 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7390 - val_digit1_loss: 0.2444 - val_digit2_loss: 0.0982 - val_digit3_loss: 0.1443 - val_digit4_loss: 0.2522 - val_digit1_acc: 0.9400 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9333\n",
      "Epoch 77/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0019 - digit1_loss: 2.2724e-04 - digit2_loss: 0.0013 - digit3_loss: 7.3094e-05 - digit4_loss: 2.5736e-04 - digit1_acc: 1.0000 - digit2_acc: 0.9995 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6790 - val_digit1_loss: 0.1961 - val_digit2_loss: 0.0866 - val_digit3_loss: 0.1411 - val_digit4_loss: 0.2553 - val_digit1_acc: 0.9600 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9433\n",
      "Epoch 78/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 6.6942e-04 - digit1_loss: 2.8522e-04 - digit2_loss: 1.9060e-04 - digit3_loss: 8.4229e-05 - digit4_loss: 1.0937e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6724 - val_digit1_loss: 0.1991 - val_digit2_loss: 0.0975 - val_digit3_loss: 0.1137 - val_digit4_loss: 0.2621 - val_digit1_acc: 0.9600 - val_digit2_acc: 0.9800 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9367\n",
      "Epoch 79/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0025 - digit1_loss: 5.4373e-04 - digit2_loss: 0.0016 - digit3_loss: 2.2760e-04 - digit4_loss: 9.6151e-05 - digit1_acc: 0.9995 - digit2_acc: 0.9985 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6882 - val_digit1_loss: 0.2046 - val_digit2_loss: 0.1078 - val_digit3_loss: 0.1144 - val_digit4_loss: 0.2614 - val_digit1_acc: 0.9633 - val_digit2_acc: 0.9800 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9300\n",
      "Epoch 80/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 9.9795e-04 - digit1_loss: 1.7189e-04 - digit2_loss: 5.6848e-04 - digit3_loss: 2.1952e-04 - digit4_loss: 3.8073e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6428 - val_digit1_loss: 0.2193 - val_digit2_loss: 0.0803 - val_digit3_loss: 0.1060 - val_digit4_loss: 0.2372 - val_digit1_acc: 0.9567 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9333\n",
      "Epoch 81/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0027 - digit1_loss: 4.6248e-04 - digit2_loss: 0.0013 - digit3_loss: 3.9842e-05 - digit4_loss: 8.7262e-04 - digit1_acc: 1.0000 - digit2_acc: 0.9990 - digit3_acc: 1.0000 - digit4_acc: 0.9995 - val_loss: 0.7388 - val_digit1_loss: 0.2394 - val_digit2_loss: 0.0943 - val_digit3_loss: 0.1416 - val_digit4_loss: 0.2635 - val_digit1_acc: 0.9533 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9433\n",
      "Epoch 82/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 6.8175e-04 - digit1_loss: 3.4558e-04 - digit2_loss: 2.2565e-04 - digit3_loss: 4.0412e-05 - digit4_loss: 7.0099e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6841 - val_digit1_loss: 0.2363 - val_digit2_loss: 0.0896 - val_digit3_loss: 0.1151 - val_digit4_loss: 0.2430 - val_digit1_acc: 0.9567 - val_digit2_acc: 0.9700 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9400\n",
      "Epoch 83/300\n",
      "2001/2001 [==============================] - 20s 10ms/step - loss: 0.0042 - digit1_loss: 0.0024 - digit2_loss: 9.4505e-04 - digit3_loss: 7.3880e-04 - digit4_loss: 3.5228e-05 - digit1_acc: 0.9995 - digit2_acc: 0.9995 - digit3_acc: 0.9990 - digit4_acc: 1.0000 - val_loss: 0.7579 - val_digit1_loss: 0.2567 - val_digit2_loss: 0.1107 - val_digit3_loss: 0.1339 - val_digit4_loss: 0.2566 - val_digit1_acc: 0.9533 - val_digit2_acc: 0.9700 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9300\n",
      "Epoch 84/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0020 - digit1_loss: 0.0014 - digit2_loss: 4.4441e-04 - digit3_loss: 3.2957e-05 - digit4_loss: 1.1155e-04 - digit1_acc: 0.9990 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6932 - val_digit1_loss: 0.2307 - val_digit2_loss: 0.1004 - val_digit3_loss: 0.1195 - val_digit4_loss: 0.2427 - val_digit1_acc: 0.9567 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9400\n",
      "Epoch 85/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001/2001 [==============================] - 21s 11ms/step - loss: 0.0014 - digit1_loss: 0.0011 - digit2_loss: 1.3461e-04 - digit3_loss: 3.4308e-05 - digit4_loss: 2.0152e-04 - digit1_acc: 0.9995 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7488 - val_digit1_loss: 0.2552 - val_digit2_loss: 0.1029 - val_digit3_loss: 0.1282 - val_digit4_loss: 0.2625 - val_digit1_acc: 0.9533 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9400\n",
      "Epoch 86/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0013 - digit1_loss: 3.4775e-04 - digit2_loss: 1.0028e-04 - digit3_loss: 8.5042e-04 - digit4_loss: 1.8315e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 0.9995 - digit4_acc: 1.0000 - val_loss: 0.7233 - val_digit1_loss: 0.2534 - val_digit2_loss: 0.0877 - val_digit3_loss: 0.1028 - val_digit4_loss: 0.2795 - val_digit1_acc: 0.9467 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9400\n",
      "Epoch 87/300\n",
      "2001/2001 [==============================] - 21s 11ms/step - loss: 5.8935e-04 - digit1_loss: 3.0898e-04 - digit2_loss: 1.1587e-04 - digit3_loss: 8.2564e-05 - digit4_loss: 8.1933e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.8059 - val_digit1_loss: 0.2964 - val_digit2_loss: 0.1034 - val_digit3_loss: 0.1182 - val_digit4_loss: 0.2880 - val_digit1_acc: 0.9400 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9400\n",
      "Epoch 88/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 3.3370e-04 - digit1_loss: 1.5811e-05 - digit2_loss: 1.6372e-04 - digit3_loss: 1.1340e-04 - digit4_loss: 4.0770e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7501 - val_digit1_loss: 0.2468 - val_digit2_loss: 0.1085 - val_digit3_loss: 0.1187 - val_digit4_loss: 0.2761 - val_digit1_acc: 0.9533 - val_digit2_acc: 0.9700 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9467\n",
      "Epoch 89/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 0.0010 - digit1_loss: 1.9783e-04 - digit2_loss: 4.2507e-04 - digit3_loss: 1.5691e-04 - digit4_loss: 2.6051e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7518 - val_digit1_loss: 0.2660 - val_digit2_loss: 0.1220 - val_digit3_loss: 0.1351 - val_digit4_loss: 0.2287 - val_digit1_acc: 0.9533 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9433\n",
      "Epoch 90/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 0.0011 - digit1_loss: 2.4328e-05 - digit2_loss: 1.7267e-04 - digit3_loss: 3.6388e-04 - digit4_loss: 5.0241e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 0.9995 - val_loss: 0.7193 - val_digit1_loss: 0.2080 - val_digit2_loss: 0.1148 - val_digit3_loss: 0.1405 - val_digit4_loss: 0.2561 - val_digit1_acc: 0.9467 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9533\n",
      "Epoch 91/300\n",
      "2001/2001 [==============================] - 21s 11ms/step - loss: 8.5122e-04 - digit1_loss: 2.5048e-04 - digit2_loss: 5.5010e-05 - digit3_loss: 1.4174e-04 - digit4_loss: 4.0399e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 0.9995 - val_loss: 0.8072 - val_digit1_loss: 0.2118 - val_digit2_loss: 0.1144 - val_digit3_loss: 0.1808 - val_digit4_loss: 0.3001 - val_digit1_acc: 0.9533 - val_digit2_acc: 0.9800 - val_digit3_acc: 0.9733 - val_digit4_acc: 0.9467\n",
      "Epoch 92/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 0.0015 - digit1_loss: 9.8541e-05 - digit2_loss: 0.0011 - digit3_loss: 2.2002e-04 - digit4_loss: 9.4150e-05 - digit1_acc: 1.0000 - digit2_acc: 0.9995 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7663 - val_digit1_loss: 0.2145 - val_digit2_loss: 0.1086 - val_digit3_loss: 0.1529 - val_digit4_loss: 0.2903 - val_digit1_acc: 0.9533 - val_digit2_acc: 0.9800 - val_digit3_acc: 0.9733 - val_digit4_acc: 0.9433\n",
      "Epoch 93/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 0.0037 - digit1_loss: 0.0027 - digit2_loss: 7.3529e-04 - digit3_loss: 1.0515e-04 - digit4_loss: 1.7534e-04 - digit1_acc: 0.9995 - digit2_acc: 0.9995 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7840 - val_digit1_loss: 0.2226 - val_digit2_loss: 0.0983 - val_digit3_loss: 0.1605 - val_digit4_loss: 0.3025 - val_digit1_acc: 0.9567 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9733 - val_digit4_acc: 0.9367\n",
      "Epoch 94/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 0.0032 - digit1_loss: 0.0015 - digit2_loss: 0.0015 - digit3_loss: 1.6401e-05 - digit4_loss: 2.1230e-04 - digit1_acc: 0.9995 - digit2_acc: 0.9990 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7992 - val_digit1_loss: 0.2472 - val_digit2_loss: 0.1121 - val_digit3_loss: 0.1568 - val_digit4_loss: 0.2830 - val_digit1_acc: 0.9467 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9367\n",
      "Epoch 95/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 0.0037 - digit1_loss: 0.0021 - digit2_loss: 6.1468e-04 - digit3_loss: 1.6652e-04 - digit4_loss: 8.4808e-04 - digit1_acc: 0.9995 - digit2_acc: 0.9995 - digit3_acc: 1.0000 - digit4_acc: 0.9995 - val_loss: 0.8298 - val_digit1_loss: 0.2648 - val_digit2_loss: 0.1325 - val_digit3_loss: 0.1727 - val_digit4_loss: 0.2599 - val_digit1_acc: 0.9433 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9467\n",
      "Epoch 96/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 7.4709e-04 - digit1_loss: 2.2439e-04 - digit2_loss: 1.6771e-04 - digit3_loss: 2.7776e-04 - digit4_loss: 7.7228e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7691 - val_digit1_loss: 0.2477 - val_digit2_loss: 0.1160 - val_digit3_loss: 0.1638 - val_digit4_loss: 0.2415 - val_digit1_acc: 0.9433 - val_digit2_acc: 0.9700 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9533\n",
      "Epoch 97/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 0.0011 - digit1_loss: 2.7138e-04 - digit2_loss: 3.5466e-04 - digit3_loss: 6.8470e-05 - digit4_loss: 4.1267e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7488 - val_digit1_loss: 0.1995 - val_digit2_loss: 0.1218 - val_digit3_loss: 0.1711 - val_digit4_loss: 0.2564 - val_digit1_acc: 0.9500 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9500\n",
      "Epoch 98/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 0.0015 - digit1_loss: 0.0012 - digit2_loss: 3.4075e-05 - digit3_loss: 2.0517e-04 - digit4_loss: 1.6203e-05 - digit1_acc: 0.9995 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7039 - val_digit1_loss: 0.1807 - val_digit2_loss: 0.1198 - val_digit3_loss: 0.1799 - val_digit4_loss: 0.2235 - val_digit1_acc: 0.9567 - val_digit2_acc: 0.9700 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9533\n",
      "Epoch 99/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 0.0011 - digit1_loss: 5.0373e-04 - digit2_loss: 2.0699e-04 - digit3_loss: 1.8659e-04 - digit4_loss: 2.3097e-04 - digit1_acc: 0.9995 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.8293 - val_digit1_loss: 0.2405 - val_digit2_loss: 0.1499 - val_digit3_loss: 0.1823 - val_digit4_loss: 0.2566 - val_digit1_acc: 0.9533 - val_digit2_acc: 0.9633 - val_digit3_acc: 0.9733 - val_digit4_acc: 0.9500\n",
      "Epoch 100/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 5.2266e-04 - digit1_loss: 1.5059e-04 - digit2_loss: 1.7606e-04 - digit3_loss: 6.3411e-05 - digit4_loss: 1.3260e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7080 - val_digit1_loss: 0.1761 - val_digit2_loss: 0.1250 - val_digit3_loss: 0.1257 - val_digit4_loss: 0.2812 - val_digit1_acc: 0.9533 - val_digit2_acc: 0.9700 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9467\n",
      "Epoch 101/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001/2001 [==============================] - 22s 11ms/step - loss: 5.8508e-04 - digit1_loss: 3.4488e-04 - digit2_loss: 2.8234e-05 - digit3_loss: 1.2540e-04 - digit4_loss: 8.6572e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7713 - val_digit1_loss: 0.2386 - val_digit2_loss: 0.1585 - val_digit3_loss: 0.1119 - val_digit4_loss: 0.2623 - val_digit1_acc: 0.9367 - val_digit2_acc: 0.9667 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9400\n",
      "Epoch 102/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 9.7307e-04 - digit1_loss: 8.1797e-04 - digit2_loss: 5.4061e-05 - digit3_loss: 7.2873e-05 - digit4_loss: 2.8169e-05 - digit1_acc: 0.9995 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.8152 - val_digit1_loss: 0.2260 - val_digit2_loss: 0.1437 - val_digit3_loss: 0.1462 - val_digit4_loss: 0.2993 - val_digit1_acc: 0.9400 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9367\n",
      "Epoch 103/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 2.6924e-04 - digit1_loss: 2.5000e-05 - digit2_loss: 1.6611e-04 - digit3_loss: 2.6696e-05 - digit4_loss: 5.1428e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7475 - val_digit1_loss: 0.1993 - val_digit2_loss: 0.1521 - val_digit3_loss: 0.1192 - val_digit4_loss: 0.2769 - val_digit1_acc: 0.9467 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9433\n",
      "Epoch 104/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 5.7208e-04 - digit1_loss: 6.5560e-05 - digit2_loss: 3.9443e-04 - digit3_loss: 6.5918e-05 - digit4_loss: 4.6165e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7937 - val_digit1_loss: 0.2443 - val_digit2_loss: 0.1596 - val_digit3_loss: 0.1219 - val_digit4_loss: 0.2679 - val_digit1_acc: 0.9467 - val_digit2_acc: 0.9633 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9400\n",
      "Epoch 105/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 4.5541e-04 - digit1_loss: 3.0207e-04 - digit2_loss: 2.2929e-05 - digit3_loss: 6.5011e-05 - digit4_loss: 6.5399e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7315 - val_digit1_loss: 0.1903 - val_digit2_loss: 0.1248 - val_digit3_loss: 0.1465 - val_digit4_loss: 0.2699 - val_digit1_acc: 0.9633 - val_digit2_acc: 0.9800 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9433\n",
      "Epoch 106/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 9.6976e-04 - digit1_loss: 1.8826e-04 - digit2_loss: 3.6886e-05 - digit3_loss: 4.4064e-04 - digit4_loss: 3.0398e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 0.9995 - digit4_acc: 1.0000 - val_loss: 0.7114 - val_digit1_loss: 0.1728 - val_digit2_loss: 0.1414 - val_digit3_loss: 0.1252 - val_digit4_loss: 0.2721 - val_digit1_acc: 0.9567 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9433\n",
      "Epoch 107/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 0.0040 - digit1_loss: 2.1138e-05 - digit2_loss: 4.3262e-05 - digit3_loss: 0.0039 - digit4_loss: 4.5046e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 0.9990 - digit4_acc: 1.0000 - val_loss: 0.7588 - val_digit1_loss: 0.2130 - val_digit2_loss: 0.1282 - val_digit3_loss: 0.1471 - val_digit4_loss: 0.2705 - val_digit1_acc: 0.9533 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9500\n",
      "Epoch 108/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 2.4946e-04 - digit1_loss: 2.3192e-05 - digit2_loss: 2.0225e-04 - digit3_loss: 7.8372e-06 - digit4_loss: 1.6176e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7817 - val_digit1_loss: 0.2434 - val_digit2_loss: 0.1242 - val_digit3_loss: 0.1441 - val_digit4_loss: 0.2700 - val_digit1_acc: 0.9500 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9500\n",
      "Epoch 109/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 5.7759e-04 - digit1_loss: 4.0490e-05 - digit2_loss: 9.3959e-05 - digit3_loss: 1.7961e-04 - digit4_loss: 2.6353e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7781 - val_digit1_loss: 0.2320 - val_digit2_loss: 0.1075 - val_digit3_loss: 0.1560 - val_digit4_loss: 0.2827 - val_digit1_acc: 0.9467 - val_digit2_acc: 0.9833 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9400\n",
      "Epoch 110/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 0.0024 - digit1_loss: 6.1793e-04 - digit2_loss: 0.0015 - digit3_loss: 8.6989e-05 - digit4_loss: 1.9179e-04 - digit1_acc: 1.0000 - digit2_acc: 0.9995 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6010 - val_digit1_loss: 0.1272 - val_digit2_loss: 0.1335 - val_digit3_loss: 0.1048 - val_digit4_loss: 0.2355 - val_digit1_acc: 0.9733 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9500\n",
      "Epoch 111/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 5.2625e-04 - digit1_loss: 2.6384e-05 - digit2_loss: 3.5924e-04 - digit3_loss: 9.8461e-05 - digit4_loss: 4.2171e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6955 - val_digit1_loss: 0.1781 - val_digit2_loss: 0.1305 - val_digit3_loss: 0.1310 - val_digit4_loss: 0.2559 - val_digit1_acc: 0.9567 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9467\n",
      "Epoch 112/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 1.9123e-04 - digit1_loss: 3.2785e-05 - digit2_loss: 6.6979e-05 - digit3_loss: 6.3196e-05 - digit4_loss: 2.8270e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7593 - val_digit1_loss: 0.1882 - val_digit2_loss: 0.1325 - val_digit3_loss: 0.1510 - val_digit4_loss: 0.2876 - val_digit1_acc: 0.9567 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9433\n",
      "Epoch 113/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 0.0013 - digit1_loss: 1.0143e-04 - digit2_loss: 6.4501e-05 - digit3_loss: 0.0011 - digit4_loss: 4.2669e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 0.9995 - digit4_acc: 1.0000 - val_loss: 0.7406 - val_digit1_loss: 0.1892 - val_digit2_loss: 0.1591 - val_digit3_loss: 0.1400 - val_digit4_loss: 0.2523 - val_digit1_acc: 0.9567 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9500\n",
      "Epoch 114/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 4.1892e-04 - digit1_loss: 2.1549e-05 - digit2_loss: 3.2335e-04 - digit3_loss: 4.6272e-06 - digit4_loss: 6.9393e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7282 - val_digit1_loss: 0.1863 - val_digit2_loss: 0.1610 - val_digit3_loss: 0.1338 - val_digit4_loss: 0.2471 - val_digit1_acc: 0.9533 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9467\n",
      "Epoch 115/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 2.4696e-04 - digit1_loss: 1.6350e-05 - digit2_loss: 6.1518e-05 - digit3_loss: 1.5739e-04 - digit4_loss: 1.1706e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6657 - val_digit1_loss: 0.1300 - val_digit2_loss: 0.1840 - val_digit3_loss: 0.1156 - val_digit4_loss: 0.2361 - val_digit1_acc: 0.9700 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9567\n",
      "Epoch 116/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 1.8036e-04 - digit1_loss: 4.1546e-05 - digit2_loss: 3.7099e-05 - digit3_loss: 5.9429e-05 - digit4_loss: 4.2285e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7704 - val_digit1_loss: 0.2373 - val_digit2_loss: 0.1533 - val_digit3_loss: 0.1359 - val_digit4_loss: 0.2440 - val_digit1_acc: 0.9500 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9600\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001/2001 [==============================] - 22s 11ms/step - loss: 3.6078e-04 - digit1_loss: 1.3872e-04 - digit2_loss: 5.8874e-05 - digit3_loss: 1.3841e-04 - digit4_loss: 2.4780e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7622 - val_digit1_loss: 0.2035 - val_digit2_loss: 0.1438 - val_digit3_loss: 0.1307 - val_digit4_loss: 0.2841 - val_digit1_acc: 0.9567 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9467\n",
      "Epoch 118/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0013 - digit1_loss: 0.0011 - digit2_loss: 9.2073e-05 - digit3_loss: 7.5258e-05 - digit4_loss: 2.5240e-05 - digit1_acc: 0.9995 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7184 - val_digit1_loss: 0.1823 - val_digit2_loss: 0.1358 - val_digit3_loss: 0.1349 - val_digit4_loss: 0.2655 - val_digit1_acc: 0.9567 - val_digit2_acc: 0.9700 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9533\n",
      "Epoch 119/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 7.5372e-04 - digit1_loss: 4.7557e-06 - digit2_loss: 4.5802e-04 - digit3_loss: 1.0087e-04 - digit4_loss: 1.9008e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6855 - val_digit1_loss: 0.1739 - val_digit2_loss: 0.1571 - val_digit3_loss: 0.1035 - val_digit4_loss: 0.2510 - val_digit1_acc: 0.9667 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9533\n",
      "Epoch 120/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 8.7887e-04 - digit1_loss: 3.4326e-04 - digit2_loss: 3.5113e-04 - digit3_loss: 1.6180e-04 - digit4_loss: 2.2688e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7373 - val_digit1_loss: 0.1738 - val_digit2_loss: 0.1895 - val_digit3_loss: 0.1006 - val_digit4_loss: 0.2734 - val_digit1_acc: 0.9700 - val_digit2_acc: 0.9633 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9467\n",
      "Epoch 121/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0025 - digit1_loss: 0.0022 - digit2_loss: 1.5266e-04 - digit3_loss: 8.9552e-05 - digit4_loss: 1.0394e-04 - digit1_acc: 0.9995 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7366 - val_digit1_loss: 0.1704 - val_digit2_loss: 0.1889 - val_digit3_loss: 0.1129 - val_digit4_loss: 0.2645 - val_digit1_acc: 0.9600 - val_digit2_acc: 0.9600 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9500\n",
      "Epoch 122/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0045 - digit1_loss: 8.5750e-04 - digit2_loss: 3.6889e-05 - digit3_loss: 9.4567e-05 - digit4_loss: 0.0035 - digit1_acc: 0.9995 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 0.9995 - val_loss: 0.7469 - val_digit1_loss: 0.2136 - val_digit2_loss: 0.1675 - val_digit3_loss: 0.1126 - val_digit4_loss: 0.2532 - val_digit1_acc: 0.9533 - val_digit2_acc: 0.9600 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9533\n",
      "Epoch 123/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0017 - digit1_loss: 7.1070e-04 - digit2_loss: 2.3877e-05 - digit3_loss: 6.2137e-04 - digit4_loss: 3.3334e-04 - digit1_acc: 0.9995 - digit2_acc: 1.0000 - digit3_acc: 0.9995 - digit4_acc: 1.0000 - val_loss: 0.7783 - val_digit1_loss: 0.2257 - val_digit2_loss: 0.1822 - val_digit3_loss: 0.1128 - val_digit4_loss: 0.2575 - val_digit1_acc: 0.9533 - val_digit2_acc: 0.9667 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9567\n",
      "Epoch 124/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0012 - digit1_loss: 4.1059e-04 - digit2_loss: 1.0694e-04 - digit3_loss: 1.6040e-04 - digit4_loss: 5.5645e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 0.9995 - val_loss: 0.8826 - val_digit1_loss: 0.2452 - val_digit2_loss: 0.2034 - val_digit3_loss: 0.1377 - val_digit4_loss: 0.2962 - val_digit1_acc: 0.9467 - val_digit2_acc: 0.9633 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9467\n",
      "Epoch 125/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 2.2580e-04 - digit1_loss: 5.7085e-05 - digit2_loss: 1.4158e-04 - digit3_loss: 1.0851e-05 - digit4_loss: 1.6281e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.9263 - val_digit1_loss: 0.2650 - val_digit2_loss: 0.2275 - val_digit3_loss: 0.1310 - val_digit4_loss: 0.3029 - val_digit1_acc: 0.9433 - val_digit2_acc: 0.9667 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9467\n",
      "Epoch 126/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 3.1994e-04 - digit1_loss: 2.2886e-05 - digit2_loss: 1.6743e-04 - digit3_loss: 4.4278e-05 - digit4_loss: 8.5347e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7936 - val_digit1_loss: 0.2262 - val_digit2_loss: 0.1916 - val_digit3_loss: 0.0960 - val_digit4_loss: 0.2798 - val_digit1_acc: 0.9533 - val_digit2_acc: 0.9700 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9567\n",
      "Epoch 127/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 7.6295e-04 - digit1_loss: 1.7549e-05 - digit2_loss: 1.6264e-04 - digit3_loss: 9.1705e-05 - digit4_loss: 4.9105e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 0.9995 - val_loss: 0.8317 - val_digit1_loss: 0.2391 - val_digit2_loss: 0.1975 - val_digit3_loss: 0.1087 - val_digit4_loss: 0.2864 - val_digit1_acc: 0.9533 - val_digit2_acc: 0.9667 - val_digit3_acc: 0.9900 - val_digit4_acc: 0.9433\n",
      "Epoch 128/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 6.7430e-04 - digit1_loss: 2.7046e-04 - digit2_loss: 9.0997e-05 - digit3_loss: 2.0631e-06 - digit4_loss: 3.1078e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.8011 - val_digit1_loss: 0.1930 - val_digit2_loss: 0.1811 - val_digit3_loss: 0.1152 - val_digit4_loss: 0.3118 - val_digit1_acc: 0.9667 - val_digit2_acc: 0.9700 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9400\n",
      "Epoch 129/300\n",
      "2001/2001 [==============================] - 21s 11ms/step - loss: 8.2392e-04 - digit1_loss: 4.8982e-05 - digit2_loss: 4.7311e-05 - digit3_loss: 4.6209e-04 - digit4_loss: 2.6554e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7542 - val_digit1_loss: 0.1635 - val_digit2_loss: 0.1639 - val_digit3_loss: 0.1148 - val_digit4_loss: 0.3120 - val_digit1_acc: 0.9700 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9900 - val_digit4_acc: 0.9467\n",
      "Epoch 130/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 7.0215e-04 - digit1_loss: 1.9396e-05 - digit2_loss: 6.3116e-04 - digit3_loss: 6.4275e-06 - digit4_loss: 4.5170e-05 - digit1_acc: 1.0000 - digit2_acc: 0.9995 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.8033 - val_digit1_loss: 0.1870 - val_digit2_loss: 0.1646 - val_digit3_loss: 0.1291 - val_digit4_loss: 0.3225 - val_digit1_acc: 0.9667 - val_digit2_acc: 0.9700 - val_digit3_acc: 0.9900 - val_digit4_acc: 0.9433\n",
      "Epoch 131/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 4.4536e-04 - digit1_loss: 8.4335e-05 - digit2_loss: 4.7913e-05 - digit3_loss: 2.6889e-04 - digit4_loss: 4.4217e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7710 - val_digit1_loss: 0.1610 - val_digit2_loss: 0.1667 - val_digit3_loss: 0.1304 - val_digit4_loss: 0.3128 - val_digit1_acc: 0.9700 - val_digit2_acc: 0.9667 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9433\n",
      "Epoch 132/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0021 - digit1_loss: 6.2647e-04 - digit2_loss: 0.0013 - digit3_loss: 1.7076e-04 - digit4_loss: 1.0175e-05 - digit1_acc: 0.9995 - digit2_acc: 0.9995 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7319 - val_digit1_loss: 0.1504 - val_digit2_loss: 0.1837 - val_digit3_loss: 0.1282 - val_digit4_loss: 0.2696 - val_digit1_acc: 0.9767 - val_digit2_acc: 0.9600 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9533\n",
      "Epoch 133/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001/2001 [==============================] - 21s 10ms/step - loss: 1.0327e-04 - digit1_loss: 3.4098e-05 - digit2_loss: 1.4388e-05 - digit3_loss: 8.9705e-06 - digit4_loss: 4.5817e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7297 - val_digit1_loss: 0.1567 - val_digit2_loss: 0.1861 - val_digit3_loss: 0.1312 - val_digit4_loss: 0.2556 - val_digit1_acc: 0.9733 - val_digit2_acc: 0.9667 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9500\n",
      "Epoch 134/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 3.6571e-04 - digit1_loss: 2.0442e-04 - digit2_loss: 1.2018e-04 - digit3_loss: 6.1393e-06 - digit4_loss: 3.4966e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7032 - val_digit1_loss: 0.1519 - val_digit2_loss: 0.1659 - val_digit3_loss: 0.1327 - val_digit4_loss: 0.2527 - val_digit1_acc: 0.9800 - val_digit2_acc: 0.9700 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9500\n",
      "Epoch 135/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 1.1819e-04 - digit1_loss: 1.4362e-05 - digit2_loss: 4.7607e-05 - digit3_loss: 1.2307e-05 - digit4_loss: 4.3914e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6732 - val_digit1_loss: 0.1415 - val_digit2_loss: 0.1451 - val_digit3_loss: 0.1321 - val_digit4_loss: 0.2545 - val_digit1_acc: 0.9767 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9533\n",
      "Epoch 136/300\n",
      "2001/2001 [==============================] - 22s 11ms/step - loss: 4.5822e-04 - digit1_loss: 1.6123e-04 - digit2_loss: 1.2980e-05 - digit3_loss: 1.0114e-04 - digit4_loss: 1.8286e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7218 - val_digit1_loss: 0.1473 - val_digit2_loss: 0.1765 - val_digit3_loss: 0.1490 - val_digit4_loss: 0.2491 - val_digit1_acc: 0.9700 - val_digit2_acc: 0.9700 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9467\n",
      "Epoch 137/300\n",
      "2001/2001 [==============================] - 21s 11ms/step - loss: 3.9403e-04 - digit1_loss: 3.1589e-05 - digit2_loss: 3.4683e-04 - digit3_loss: 7.9346e-06 - digit4_loss: 7.6701e-06 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7236 - val_digit1_loss: 0.1642 - val_digit2_loss: 0.1656 - val_digit3_loss: 0.1534 - val_digit4_loss: 0.2403 - val_digit1_acc: 0.9633 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9500\n",
      "Epoch 138/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 4.3031e-04 - digit1_loss: 7.0989e-06 - digit2_loss: 1.6735e-05 - digit3_loss: 6.2130e-06 - digit4_loss: 4.0026e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7840 - val_digit1_loss: 0.1876 - val_digit2_loss: 0.1681 - val_digit3_loss: 0.1460 - val_digit4_loss: 0.2823 - val_digit1_acc: 0.9600 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9767 - val_digit4_acc: 0.9400\n",
      "Epoch 139/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 2.6426e-04 - digit1_loss: 6.3523e-05 - digit2_loss: 6.2524e-05 - digit3_loss: 3.8762e-05 - digit4_loss: 9.9448e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.8304 - val_digit1_loss: 0.2011 - val_digit2_loss: 0.1467 - val_digit3_loss: 0.1513 - val_digit4_loss: 0.3312 - val_digit1_acc: 0.9600 - val_digit2_acc: 0.9800 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9367\n",
      "Epoch 140/300\n",
      "2001/2001 [==============================] - 21s 11ms/step - loss: 1.8806e-04 - digit1_loss: 6.7822e-05 - digit2_loss: 5.5777e-05 - digit3_loss: 3.2612e-05 - digit4_loss: 3.1847e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7089 - val_digit1_loss: 0.1532 - val_digit2_loss: 0.1550 - val_digit3_loss: 0.1143 - val_digit4_loss: 0.2865 - val_digit1_acc: 0.9700 - val_digit2_acc: 0.9800 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9400\n",
      "Epoch 141/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0014 - digit1_loss: 0.0012 - digit2_loss: 1.2679e-04 - digit3_loss: 4.2283e-05 - digit4_loss: 2.0225e-05 - digit1_acc: 0.9995 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6896 - val_digit1_loss: 0.1702 - val_digit2_loss: 0.1618 - val_digit3_loss: 0.1021 - val_digit4_loss: 0.2556 - val_digit1_acc: 0.9633 - val_digit2_acc: 0.9667 - val_digit3_acc: 0.9900 - val_digit4_acc: 0.9467\n",
      "Epoch 142/300\n",
      "2001/2001 [==============================] - 21s 11ms/step - loss: 6.0364e-04 - digit1_loss: 6.6116e-05 - digit2_loss: 4.2103e-04 - digit3_loss: 4.4313e-05 - digit4_loss: 7.2173e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6781 - val_digit1_loss: 0.1513 - val_digit2_loss: 0.1471 - val_digit3_loss: 0.1208 - val_digit4_loss: 0.2590 - val_digit1_acc: 0.9767 - val_digit2_acc: 0.9700 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9500\n",
      "Epoch 143/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 1.6765e-04 - digit1_loss: 1.8458e-05 - digit2_loss: 9.3242e-05 - digit3_loss: 5.2082e-05 - digit4_loss: 3.8718e-06 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6930 - val_digit1_loss: 0.1677 - val_digit2_loss: 0.1534 - val_digit3_loss: 0.1186 - val_digit4_loss: 0.2534 - val_digit1_acc: 0.9667 - val_digit2_acc: 0.9600 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9467\n",
      "Epoch 144/300\n",
      "2001/2001 [==============================] - 21s 11ms/step - loss: 0.0016 - digit1_loss: 0.0015 - digit2_loss: 6.8246e-06 - digit3_loss: 1.0358e-05 - digit4_loss: 1.2503e-04 - digit1_acc: 0.9990 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7292 - val_digit1_loss: 0.1988 - val_digit2_loss: 0.1514 - val_digit3_loss: 0.1184 - val_digit4_loss: 0.2607 - val_digit1_acc: 0.9567 - val_digit2_acc: 0.9667 - val_digit3_acc: 0.9800 - val_digit4_acc: 0.9467\n",
      "Epoch 145/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 3.1206e-04 - digit1_loss: 3.5889e-05 - digit2_loss: 7.1914e-06 - digit3_loss: 2.5892e-04 - digit4_loss: 1.0059e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6769 - val_digit1_loss: 0.1841 - val_digit2_loss: 0.1546 - val_digit3_loss: 0.0798 - val_digit4_loss: 0.2583 - val_digit1_acc: 0.9667 - val_digit2_acc: 0.9667 - val_digit3_acc: 0.9900 - val_digit4_acc: 0.9433\n",
      "Epoch 146/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 0.0036 - digit1_loss: 1.5673e-04 - digit2_loss: 0.0035 - digit3_loss: 3.2592e-05 - digit4_loss: 6.5335e-06 - digit1_acc: 1.0000 - digit2_acc: 0.9990 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7920 - val_digit1_loss: 0.2135 - val_digit2_loss: 0.1618 - val_digit3_loss: 0.1114 - val_digit4_loss: 0.3054 - val_digit1_acc: 0.9633 - val_digit2_acc: 0.9700 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9400\n",
      "Epoch 147/300\n",
      "2001/2001 [==============================] - 21s 11ms/step - loss: 6.7803e-05 - digit1_loss: 1.4784e-05 - digit2_loss: 2.1558e-05 - digit3_loss: 1.7482e-05 - digit4_loss: 1.3980e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7749 - val_digit1_loss: 0.2296 - val_digit2_loss: 0.1518 - val_digit3_loss: 0.1112 - val_digit4_loss: 0.2822 - val_digit1_acc: 0.9600 - val_digit2_acc: 0.9667 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9467\n",
      "Epoch 148/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 9.8350e-04 - digit1_loss: 5.3828e-05 - digit2_loss: 3.7236e-04 - digit3_loss: 4.1952e-04 - digit4_loss: 1.3779e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 0.9995 - digit4_acc: 1.0000 - val_loss: 0.7157 - val_digit1_loss: 0.1878 - val_digit2_loss: 0.1344 - val_digit3_loss: 0.1229 - val_digit4_loss: 0.2707 - val_digit1_acc: 0.9667 - val_digit2_acc: 0.9667 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9467\n",
      "Epoch 149/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001/2001 [==============================] - 21s 11ms/step - loss: 8.8021e-04 - digit1_loss: 2.4365e-05 - digit2_loss: 4.0900e-04 - digit3_loss: 2.7333e-04 - digit4_loss: 1.7352e-04 - digit1_acc: 1.0000 - digit2_acc: 0.9995 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6909 - val_digit1_loss: 0.1834 - val_digit2_loss: 0.1265 - val_digit3_loss: 0.1097 - val_digit4_loss: 0.2714 - val_digit1_acc: 0.9667 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9433\n",
      "Epoch 150/300\n",
      "2001/2001 [==============================] - 21s 11ms/step - loss: 5.0385e-04 - digit1_loss: 1.4941e-05 - digit2_loss: 3.9125e-04 - digit3_loss: 7.1648e-06 - digit4_loss: 9.0488e-05 - digit1_acc: 1.0000 - digit2_acc: 0.9995 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6727 - val_digit1_loss: 0.1631 - val_digit2_loss: 0.1324 - val_digit3_loss: 0.1069 - val_digit4_loss: 0.2703 - val_digit1_acc: 0.9667 - val_digit2_acc: 0.9700 - val_digit3_acc: 0.9900 - val_digit4_acc: 0.9433\n",
      "Epoch 151/300\n",
      "2001/2001 [==============================] - 21s 11ms/step - loss: 4.6825e-05 - digit1_loss: 7.5010e-06 - digit2_loss: 5.8494e-06 - digit3_loss: 1.4836e-05 - digit4_loss: 1.8638e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7408 - val_digit1_loss: 0.1866 - val_digit2_loss: 0.1393 - val_digit3_loss: 0.1251 - val_digit4_loss: 0.2899 - val_digit1_acc: 0.9567 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9400\n",
      "Epoch 152/300\n",
      "2001/2001 [==============================] - 21s 11ms/step - loss: 2.1444e-04 - digit1_loss: 1.2936e-04 - digit2_loss: 8.6326e-06 - digit3_loss: 6.0843e-05 - digit4_loss: 1.5605e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7043 - val_digit1_loss: 0.1916 - val_digit2_loss: 0.1474 - val_digit3_loss: 0.1246 - val_digit4_loss: 0.2408 - val_digit1_acc: 0.9633 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9500\n",
      "Epoch 153/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 7.4228e-04 - digit1_loss: 6.8397e-04 - digit2_loss: 7.0942e-06 - digit3_loss: 9.1133e-07 - digit4_loss: 5.0299e-05 - digit1_acc: 0.9995 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6889 - val_digit1_loss: 0.1862 - val_digit2_loss: 0.1509 - val_digit3_loss: 0.1159 - val_digit4_loss: 0.2360 - val_digit1_acc: 0.9600 - val_digit2_acc: 0.9667 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9533\n",
      "Epoch 154/300\n",
      "2001/2001 [==============================] - 21s 11ms/step - loss: 2.0280e-04 - digit1_loss: 1.8255e-04 - digit2_loss: 5.3895e-06 - digit3_loss: 1.3255e-05 - digit4_loss: 1.6067e-06 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6974 - val_digit1_loss: 0.1930 - val_digit2_loss: 0.1353 - val_digit3_loss: 0.1135 - val_digit4_loss: 0.2555 - val_digit1_acc: 0.9667 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9900 - val_digit4_acc: 0.9400\n",
      "Epoch 155/300\n",
      "2001/2001 [==============================] - 21s 11ms/step - loss: 2.4861e-04 - digit1_loss: 1.1772e-05 - digit2_loss: 2.1448e-04 - digit3_loss: 2.0262e-05 - digit4_loss: 2.0987e-06 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7369 - val_digit1_loss: 0.2102 - val_digit2_loss: 0.1340 - val_digit3_loss: 0.1209 - val_digit4_loss: 0.2718 - val_digit1_acc: 0.9500 - val_digit2_acc: 0.9800 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9400\n",
      "Epoch 156/300\n",
      "2001/2001 [==============================] - 21s 11ms/step - loss: 8.7037e-05 - digit1_loss: 5.6728e-06 - digit2_loss: 2.4482e-05 - digit3_loss: 3.9543e-05 - digit4_loss: 1.7338e-05 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7238 - val_digit1_loss: 0.2057 - val_digit2_loss: 0.1443 - val_digit3_loss: 0.1325 - val_digit4_loss: 0.2413 - val_digit1_acc: 0.9567 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9833 - val_digit4_acc: 0.9533\n",
      "Epoch 157/300\n",
      "2001/2001 [==============================] - 21s 11ms/step - loss: 4.0643e-05 - digit1_loss: 1.0221e-05 - digit2_loss: 1.1769e-05 - digit3_loss: 1.3008e-05 - digit4_loss: 5.6462e-06 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6723 - val_digit1_loss: 0.1840 - val_digit2_loss: 0.1277 - val_digit3_loss: 0.1142 - val_digit4_loss: 0.2463 - val_digit1_acc: 0.9633 - val_digit2_acc: 0.9800 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9567\n",
      "Epoch 158/300\n",
      "2001/2001 [==============================] - 21s 11ms/step - loss: 6.8238e-04 - digit1_loss: 4.8047e-06 - digit2_loss: 2.5851e-04 - digit3_loss: 1.3219e-05 - digit4_loss: 4.0585e-04 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 0.9995 - val_loss: 0.6734 - val_digit1_loss: 0.1670 - val_digit2_loss: 0.1445 - val_digit3_loss: 0.1102 - val_digit4_loss: 0.2516 - val_digit1_acc: 0.9667 - val_digit2_acc: 0.9767 - val_digit3_acc: 0.9900 - val_digit4_acc: 0.9467\n",
      "Epoch 159/300\n",
      "2001/2001 [==============================] - 21s 11ms/step - loss: 6.4966e-04 - digit1_loss: 1.0210e-04 - digit2_loss: 4.4116e-04 - digit3_loss: 3.9448e-06 - digit4_loss: 1.0245e-04 - digit1_acc: 1.0000 - digit2_acc: 0.9995 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.7071 - val_digit1_loss: 0.1770 - val_digit2_loss: 0.1632 - val_digit3_loss: 0.1173 - val_digit4_loss: 0.2495 - val_digit1_acc: 0.9667 - val_digit2_acc: 0.9700 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9467\n",
      "Epoch 160/300\n",
      "2001/2001 [==============================] - 21s 10ms/step - loss: 1.1582e-04 - digit1_loss: 2.3836e-05 - digit2_loss: 7.0814e-05 - digit3_loss: 1.1784e-05 - digit4_loss: 9.3895e-06 - digit1_acc: 1.0000 - digit2_acc: 1.0000 - digit3_acc: 1.0000 - digit4_acc: 1.0000 - val_loss: 0.6936 - val_digit1_loss: 0.1509 - val_digit2_loss: 0.1525 - val_digit3_loss: 0.1250 - val_digit4_loss: 0.2651 - val_digit1_acc: 0.9733 - val_digit2_acc: 0.9733 - val_digit3_acc: 0.9867 - val_digit4_acc: 0.9533\n"
     ]
    }
   ],
   "source": [
    "history = my_model.fit_generator(data_generator(\"real_train\"), samples_per_epoch=len(train_datas), epochs=300, validation_data=data_generator(validate_folder_path), validation_steps=len(val_datas), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = my_model.fit_generator(data_gen_dynamic(128), samples_per_epoch=256, epochs=300, validation_data=data_generator(validate_folder_path), validation_steps=len(val_datas), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = my_model.fit_generator(data_generator(train_folder_path), samples_per_epoch=len(train_datas), epochs=100, validation_data=data_generator(validate_folder_path), validation_steps=len(val_datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = my_model.fit(train_data, train_label, validation_data=(val_data, val_label), batch_size=32, epochs=100, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = (np.array(history.history['digit1_acc'])+np.array(history.history['digit2_acc'])+np.array(history.history['digit3_acc'])+np.array(history.history['digit4_acc']))/4\n",
    "val_acc = (np.array(history.history['val_digit1_acc'])+np.array(history.history['val_digit2_acc'])+np.array(history.history['val_digit3_acc'])+np.array(history.history['val_digit4_acc']))/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(history.history['digit1_acc'])\n",
    "# plt.plot(history.history['val_digit1_acc'])\n",
    "# plt.plot(history.history['digit2_acc'])\n",
    "# plt.plot(history.history['val_digit2_acc'])\n",
    "# plt.plot(history.history['digit3_acc'])\n",
    "# plt.plot(history.history['val_digit3_acc'])\n",
    "# plt.plot(history.history['digit4_acc'])\n",
    "# plt.plot(history.history['val_digit4_acc'])\n",
    "plt.plot(acc)\n",
    "plt.plot(val_acc)\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.save('my_model_20190201.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = my_model.predict(np.asarray([train_data[1]]))\n",
    "for item in predict_test:\n",
    "    index = np.argmax(item)\n",
    "    print(alphabet[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 1021.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      "4\n",
      "P\n",
      "Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_data_set = preprocessing(\"test_set\")\n",
    "result =  my_model.predict(test_data_set)\n",
    "for item in result:\n",
    "    index = np.argmax(item)\n",
    "    print(alphabet[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 51, 137, 3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_set.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
